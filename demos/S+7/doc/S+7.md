---
title: S+7 : an OULIPIAN word game
author: Guy Lapalme
description: combined use of the Stanza parser and pyrealb
keywords: OULIPO, S+7, word game, sentence transformation
---

<center style="font-size:3em; font-family: 'Open Sans'; font-weight: bold">S+7 : an <i>OULIPIAN</i> word game</center>
<center><a href="mailto:lapalme@iro.umontreal.ca">Guy Lapalme</a><br/>RALI-DIRO<br/>Université de Montréal<br/>April 2025</center>

This demo implements the [*S+7* word game](https://www.oulipo.net/fr/contraintes/s7) that was originally introduced by Jean Lescure, an OULIPO member, in 1961.

OULIPO (Ouvroir de littérature potentielle) is a group of French-speaking writers and mathematicians who create texts according to constraints such as avoiding a specific letter (l[ipogram)](https://www.oulipo.net/fr/contraintes/lipogramme), or starting all words with the same letter ([tautogram](https://www.oulipo.net/fr/contraintes/tautogramme)). In English, this group would be WOPOLI (Workshop for Potential Literature).

In their initial proposal, they suggested a constraint called *S+7*, where each substantive (common noun) is replaced by the seventh common noun that follows it in a specific dictionary. This constraint can also be applied to other parts of speech, such as verbs (except for auxiliaries) and adjectives, which are replaced by the seventh word of the same lexical category in the lexicon.

In our implementation of this constraint, the input text is first parsed with [Stanza](https://stanfordnlp.github.io/stanza/) to create a dependency structure.  This structure is used as input for a program that creates an expression for realization using  [pyrealb](https://pypi.org/project/pyrealb/), a Python package that allows for English and French sentence realization. This expression is modified according to the *S+7* rule for the final sentence realization by *pyrealb*. 

We first recall what is  *pyrealb*, then we describe the transformation process and its implementation.

# *pyrealb* for sentence realization

*pyrealb* is a sentence realizer that uses the following components for both English and French:

- a *lexicon*  (a *JSON* file) defining the word category, gender, number, declension and conjugation rule number and other features needed to produce the final token. To ease the management and manual searching of entries, the JSON file is alphabetically sorted. Lists of nouns, verbs, and adjectives are extracted, maintaining this order for finding the seventh next word of the same category.
- *morphological rules* (a *JSON* file) to determine the appropriate word forms, such as plurals and conjugations;
- *syntactic rules* (*Python* functions) to build sentence structures from terminals and to properly order words within a sentence, performing the most common agreements between constituents and carrying out other useful sentence organization tasks, such as managing coordination or applying sentence transformations. 

*pyrealb* accepts either a *Constituent* or a *Dependent* notation for building sentences. In this demo, we use the *Dependent* notation because it is closer to the dependency format created by Stanza from the input text. The data structure is built by functions whose name recall symbols that are typically used by linguists for these concepts:

- `Terminal`: `N` (noun), `V` (verb), `A` (adjective), `D` (determiner), `Pro` (pronoun), `Adv` (adverb), `P` (preposition), `C` (conjunction), `NO` (number), `DT` (date), `Q` (quoted/canned text). A terminal is created with a single parameter its lemma, most often a string, 
- `Dependent` for combining its parameters, i.e., terminals and other `Dependent`s: `root` (root), `subj` (subject), `det` (determiner), `mod` (modification), `comp` (complement) and `coord` (coordination). Only a small subset of the conventional universal dependencies relation names is used for the realization process. A `Dependent` is created with its head as a first parameter, optionally followed by other dependents.

To produce the text string corresponding to the structure of a `Terminal` or a `Dependent`, the `realize()` method of `Terminal`, but more often of a `Dependent`, must be called.  *pyrealb* keeps track of the current language set by either `loadEn()` or `loadFr()`. `Terminal`s and `Dependent`s are then associated with this language, ensuring that the appropriate morphological rules are applied at realization time. 

Features are added to these structures using the dot notation to modify their properties. For `Terminals`, their person, number, gender can be specified. For `Dependent`s, the sentence may be negated , modified by a modal or set to a passive mode. 

One challenge in dependency syntax is to specify word ordering.  *pyrealb* uses straightforward rules for ordering words: determiners and subjects are placed before the head, while modifiers and complements are placed after the head. When multiple dependents are specified, they are realized in the order of their appearance in the expression. It is possible to change this default ordering with the `.pos(...)` feature and the parameters `pre` (before) or `pos` (after).

The following is an example of a *pyrealb* expression with its realization as a sentence.

```python
loadEn()
print(
  root(V("jump").t("ps"),          # verb to the simple past
       subj(N("cat").n("p"),       # subject to plural
            det(D("a"))),          # undefinite determiner
       comp(P("on"),               # verb prepositional complement 
            mod(N("mat"),          # modified by a noun
                det(D("the")),
                mod(A("good").f("su"))))  # itself modified by an adjective
       ).typ({"neg":True})         # the whole sentence is negated
)
#  Cats did not jump on the best mat.
```

The adjective *good* (realized as *best*) appears before the head because adjectives in English are placed before the noun.

# Sentence transformation

Creating an *S+7* sentence from the previous expression is only a matter of changing the nouns *cat* and *mat* by *cataleptic* and *matchmaker* (they are the 7th following nouns after *cat* and *mat*), the verb *jump* by *keep* and adjective *good* by *grey-headed*.  This creates the following expression, shown with its realization.

```python
root(V("keep").t("ps"),
     subj(N("cataleptic").n("p"),
          det(D("a"))),
     comp(P("on"),
          mod(N("matchmaker"),
              det(D("the")),
              mod(A("good-time").f("su"))))
     ).typ({"neg":true})
# Cataleptics did not keep on the most good-time matchmaker.
```

Notice that this constraint cannot be implemented by replacing strings alone. The original inflections in the source text, such as *good* and *gray-headed*, must be maintained in the target text. In English, this is relatively simple.  In French, inflection rules are more complex. Gender agreements must be propagated between nouns, adjectives and determiners. Here is an example of a French sentence with its S+7 transformation.

<div style="border:thin solid black; text-align=center; padding:5px"><I>Un vieil homme a chanté sur la grande avenue.</I> &rarr; 
  <i>Une vile homochromie a chapitré sur le grandissant aveugle.</i> 
</div>
*homme*, of grammatical gender masculine, being changed to *homochromie*, a feminine noun, the determiner *un* and the adjective *vil*  must also be declined as feminine. 

*S+7* is usually applied to whole texts such as in the French fable *La cigale et la fourmi* de *Jean de La Fontaine*. The second line of the following table shows the first two verses that can be compared with [Raymond Queneau's version](https://www.oulipo.net/fr/contraintes/s7) : *La cimaise et la fraction*. The third line gives the [English translation by Robert Stokes](https://www.babelmatrix.org/works/fr/La_Fontaine%2C_Jean_de-1621/La_Cigale_et_la_Fourmi/en/5027-The_grasshopper_and_the_ant). In this example, the fable has been slightly modified so that Stanza can better segment sentences and identify common nouns that *pyrealb* can recognize and transform. Our objective is to illustrate the transformation method, not to reproduce the original verbatim.

|                           Original                           |                             S+7                              |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| **La cigale et la fourmi.<br />**La cigale avait chanté tout l'été. <br/>Elle se trouva fort dépourvue <br/>quand la bise fut venue. <br />Pas un seul petit morceau <br />de mouche ou de vermisseau. | **La ciguë et le fourneau. <br />**La ciguë avait chapitré toxicomaniaque l'étendoir.<br />Elle se tuberculina fort déprisé <br />quand le bison eut verdoyé. <br />Pas un sexuel pétrifiant mordillage <br />de mouchoir ou de vernier. |
| **The grasshopper and the ant.<br />**The grasshopper had sung<br /> all summer long, <br />She found herself most destitute, <br />when the north wind came. <br />Not a morsel to her name <br />of either fly or worm. | **The gratitude and the antechamber. <br />**The gratitude had <br />long sired all sumpter. <br />She fitted herself most detergent, <br />when the north windflower commented. <br />Not a mortgagor to her nankeen <br />of either flyleaf or worship. |

In French, *tout* before *l'été*, should have been tagged as a determiner, but Stanza tagged it as an adjective. This is why it was transformed. Most often, *tout* is an adjective, but not in this particular poetry piece.

# Transformation Implementation

To achieve the *S+7* transformation, we must not only identify the lemma associated with each input word, but also determine the grammatical relationships between them. We can then ensure that the correct grammatical agreements are performed in the output text.

To do this, we use the [Stanza parser](https://stanfordnlp.github.io/stanza/) to split the text into sentences and tokens, retrieve the lemmas, and determine the dependencies between them. Based on this information, we create a *pyrealb* expression corresponding to the original sentence. For each noun, verb and adjective, the lemma is changed to the corresponding seventh noun, verb or adjective in the *pyrealb* lexicon.  This expression is used to construct a sentence. 

We now provide a more detailed explanation of this process, which is identical in French and English. To demonstrate  the change, we use the opening sentence of section 2: *Cats did not jump on the best mat.*

Stanza returns a dependency parse whose graph  is shown in the following picture. 

![](/Users/lapalme/Dropbox/S+7/doc/example-UD.png)

The following gives the corresponding *conventional* [CONLL-U format](https://universaldependencies.org/format.html) picture, along with a comment recalling the original sentence.

```
# text = Cats did not jump on the best mat.
1⋅Cats⋅cat⋅NOUN⋅NNS⋅Number=Plur⋅4⋅nsubj⋅_⋅_
2⋅did⋅do⋅AUX⋅VBD⋅Mood=Ind|Number=Plur|Person=3|Tense=Past|VerbForm=Fin⋅4⋅aux⋅_⋅_
3⋅not⋅not⋅PART⋅RB⋅Polarity=Neg⋅4⋅advmod⋅_⋅_
4⋅jump⋅jump⋅VERB⋅VB⋅VerbForm=Inf⋅0⋅root⋅_⋅_
5⋅on⋅on⋅ADP⋅IN⋅_⋅8⋅case⋅_⋅_
6⋅the⋅the⋅DET⋅DT⋅Definite=Def|PronType=Art⋅8⋅det⋅_⋅_
7⋅best⋅good⋅ADJ⋅JJS⋅Degree=Sup⋅8⋅amod⋅_⋅_
8⋅mat⋅mat⋅NOUN⋅NN⋅Number=Sing⋅4⋅obl⋅_⋅_
9⋅.⋅.⋅PUNCT⋅.⋅_⋅4⋅punct⋅_⋅_
```

Each line corresponds to token with the following tab separated fields (each tab is displayed here as "`⋅`"):

- *id* : position of the token, the first token being 1
- *text* : the token as it was encountered in the input  
- *lemma*: the lemma corresponding to the *text*
- *upos*: part of speech of the token
- an extended part of speech : unused in this application
- *feats*: list of morphological features such as gender, number, person, etc.
- *head* : head token of the current token: an *id* or 0 for the root.
- *deprel* : dependency relation between the head and this token
- the last two fields are ignored in this application 

Stanza provides a Python API for retrieving the values of these fields.

We first build a *Universal Dependency* (UD) tree using the information in the head field data of each token. Each edge is labeled with the *corresponding deprel*. The tokens of our example, as shown in the previous image, can be represented as follows:

```python
  ┌─── nsubj → Cats : cat:NOUN:{'Number': 'Plur'}
  ├─── aux → did : do:AUX:{'Mood': 'Ind', 'Number': 'Plur', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}
  ├─── advmod → not : not:PART:{'Polarity': 'Neg'}
──├─ root → jump : jump:VERB:{'VerbForm': 'Inf'}
  │ ┌─── case → on : on:ADP:{}
  │ ├─── det → the : the:DET:{'Definite': 'Def', 'PronType': 'Art'}
  │ ├─── amod → best : good:ADJ:{'Degree': 'Sup'}
  ├─└─ obl → mat : mat:NOUN:{'Number': 'Sing'}
  └─── punct → . : .:PUNCT:{}
```

To recover the original sentence, read the tokens (the word after the arrow) from top to bottom. In the case of a [projective tree](https://web.stanford.edu/~jurafsky/slp3/old_oct19/15.pdf), this in-order traversal of the tree starting from the root recreates the words in the original order. This is not always the case, for example parsing  *JetBlue canceled our flight this morning which was already late.* , returns a non-projective UD tree that is realized as *JetBlue canceled our flight which was already late this morning.*

The following *pyrealb* expression is built by traversing this dependency tree and applying the transformation described in the next section: 

```swift
root(V("jump").t('ps').pe(3).n('p'),
     subj(N("cat").n('p')),
     comp(P("on"),
          comp(N("mat").n('s'),
               det(D("the")),
               mod(A("good").f('su')).pos('pre')))
    ).typ({'neg': True})
```

This  tree differs slightly from the tree shown in section 1:

- the plural indefinite determiner is not shown, as it could not be detected in the input.;
- there are some spurious option calls corresponding to the systematic translation of UD features.

For this state*ment,* the initial sentence is replicated exactly. However, this may not always be the case, especially for non-projective relationships or in cases of lemmatization or head errors. 

Comparing the realization of the resulting expression with the original sentence can be used to verify the extraction of lemmas and features by Stanza, similar to [how we validated Universal Dependencies annotations](https://aclanthology.org/2021.udw-1.9/). The advantage of this regeneration process is that it is easier to spot errors in a realized text than in a list of features or head links. 

To obtain the *S+7* text, the *pyrealb* expression is navigated replacing each noun, adjective and verb with the seventh following word of the same category in the *pyrealb* lexicon.

## Transformation from Universal Dependencies to *pyrealb* Dependent 

Since Stanza excels at parsing input with remarkable precision and pyre*alb con*sistently produces sentences, the challenge is to map a *UD* tree to a *pyrealb* expression. This transformation is *ba*sed on a Python adaptation of the methods used in [our previous system](http://rali.iro.umontreal.ca/JSrealB/current/demos/UDregenerator/UDregenerator-en.html), which had been developed in JavaScript.

[^*]: The development of this demo was an occasion to revisit and improve the initial transformation process 

### Terminal Transformation

Each UD token occurs as a head of *pyrealb* `Dependent`. The first step is to map the UD `upos` field to the appropriate *pyrealb* `Terminal` e.g., `NOUN` to `N`, `ADJ` to `A`, `VERB` to `V`, etc. 

Stanza identifies a lemma corresponding to the form found in the text. If the lemma is found in the *pyrealb* lexicon, it is used as is. However, if the Stanza lemma is not in the *pyrealb* lexicon but corresponds to an inflected form, we use the lemma of the inflected form in the *pyrealb* lexicon.  For example, in French *prêteuse*, tagged as an adjective by Stanza, must be mapped to the feminine singular of *the* adjective lemma pr*êteur*.

The mapping of pronouns is quite involved, since the lemmas chosen by Stanza are often different, but legitimate, from those used in *pyrealb*. If no appropriate lemma is found, a quoted terminal `Q(…)` will be returned, which will appear verbatim in the output.

A language-specific mapping must also be established between UD features, such as `Person=2` and `Number=Plur`, and the corresponding *pyrealb* options `.pe (2).n(“p”)`. In some cases, more than one feature must be combined into a single option, such as `VerbForm=Part` and `Tense=Past` into `.t("pp")`.

Occasionally, multiple tokens are required for a single option. Consider the case of the English future tense, denoted by the `.t("f")` method. It requires identifying the *will* auxiliary, which is subsequently eliminated from the Universal Dependencies (UD) syntax tree upon adding the relevant characteristic to the verb. In French, the *avoir* auxiliary needs to be deleted and merged with the verb’s data to get *temps composés* such as *passé composé* or *plus-que-parfait*.

In the case of *S+7*, it is crucial to note that the features `Gender` and `Number` of adjectives and determiners should not be mapped. Instead, their values will be derived from the gender and number of the newly introduced noun. This rule primarily applies to French, although in English, we must pay attention when switching between plural countable and uncountable nouns, as they may need to remain singular. 

### Dependent transformation

To convert a node in a UD tree into a `Dependent`, the dependent type is determined using a predefined correspondence between core dependent relations, such as *nsubj* and *csubj*, which map to `subj`, or *obj*, *ccomp*, *iobj*, and *xcomp, which map* to `comp`, or nominal dependents *nmod* and *amod, which map* to `mod`, and so on.

Copulas, such as *The cat is black,* must be dealt with specially: in a UD tree, the attribute (*black*) is the root, but in *pyrealb*, the root must be the copula (*be*) so that the agreement between the subject and the copula is correct. Moreover, in French, attributes can agree with the subject of the copula. The UD tree is thus modified so that the original UD *ro*ot (the attribute) becomes the complement. The original subject is then removed from the original root and added to the left of the new root, the copula.

Then, there is a stage that is contingent on the chosen language, where it looks for particular structures to generate possible sentences.

- in English: we check for modals,  progressive, perfect tenses and interrogatives each of these possibly negated. 
- in French: we check for negation composed of two words (e.g. *ne* ... *pas* or *ne* ... *plus*), interrogative by verb and subject inversion, and remove *se* for strictly reflexive verbs because it will be realized automatically by *pyrealb*.

After the head is changed, it becomes the head of the `Dependent`. The children of the UD node are then processed recursively and inserted into this `Dependent`.

### Coordination translation

Addressing coordination involves performing tree manipulation operations due to the significant structural differences between coordination in a UD tree and the expected form in *pyrealb*. This transformation is language-independent.

In a UD tree, all coordinating conjunctions are connected to the initial conjunction in a *cluster, indi*cated by the `conj` relationship, as demonstrated in the diagram on the left. In this cas*e, rabbit* and *dog* are joined to *cat*. The final conjunct is connected to the preceding conjunction with a `cc` relation, here *and*.  

In *pyrealb*, as shown in the diagram on the right, the head of the `coord` Dependent is the conjunction `and`; each conjunct is a `Dependent` (here, a `subj`) that is added as a child of the `coord`. The commas in the original UD tree are also removed. They will be added during the *pyrealb* realization.

<img src="/Users/lapalme/Dropbox/S+7/doc/coord-UD.png" style="zoom:45%;" /><img src="/Users/lapalme/Dropbox/S+7/doc/coord-pyrealb.png" style="zoom:45%;" />

```python
root(V("run").t('p'),
     coord(C("and"),
           subj(N("cat").n('s'),
                det(D("the"))),
           subj(N("rabbit").n('s'),
                det(D("the"))),
           subj(N("dog").n('s'),
                det(D("the")))),
     comp(N("park").n('s'),
          mod(P("in")).pos('pre'),
          det(D("the"))))
# The cat, the rabbit and the dog run in the park.
```

The check for coordination is performed at the start of each sentence. Each conjunct is transformed according the algorithms described above. The transformed conjuncts are then combined for the final realization.

## Limitations

The result of *S+7* is heavily influenced by the output of the Stanza parser, which is generally reliable but can 
have limitations or ambiguities that it is unable to resolve in some cases. In particular, French lemmatization or 
tagging is sometimes *surprising* (e.g. *paier* as lemma for *paierai*, *aimes* tagged as plural), although the 
maintainer of Stanza improved it after some of our suggestions, when we noticed systematic errors.

This program can also be used as a tool for recreating the original sentence from the information found in the parse results, ignoring the S+7 transformation. The differences between the original sentence and the generated one can be traced back to errors or limitations in the Stanza lemmatization or feature identification process.

Another drawback is the fact that the initial formatting of the source is lost. Stanza uses its own algorithms to split the text into sentences and then into tokens; it processes *plain text*, ignoring any formatting except for punctuation.  So a text is processed sentence by sentence, ignoring the paragraph structure. However, since Stanza provides the character positions of the start and end of each token, it would be possible to restore some of the original formatting by processing each paragraph separatly. We leave this as *a future project*.

# Conclusion

This document explained how to implement the Oulipian *S+7* rule for French or English texts. Implementing this approach using string substitution might have seemed straightforward, but we demonstrated that it was more complex than it appeared.

To ensure grammatical accuracy, one must consider connections between words. We use Stanza’s syntactic data to parse the source text, converting it into a *pyrealb* expression. This expression can then be used to recreate the original sentence. To apply the *S+7* rule, the lemmas of this expression must be modified to create a new expression that produces a transformed sentence.

This exercise was beneficial for us, as it brought up a few problems in the *pyrealb* realization process, but it also highlighted some limitations in the Stanza lemmatization process. It also allowed us to revisit our original UD 

As we had [previously developed a method](https://aclanthology.org/2021.udw-1.9/ "Validation of Universal Dependencies by regeneration - ACL Anthology") for dealing with [manual UD annotations](https://universaldependencies.org), we noticed that the annotations produced by Stanza seemed more systematic than those created by different human annotators, making them somewhat easier to manage.

# Running the system

- `./s_plus_7.py en story.txt` 

  The content of the English file *story.txt*  is first split into sentences. Each sentence is displayed, followed by its *regeneration* for comparison with the original, Then each content word is *shifted* by 7 words..

- `./s_plus_7.py -n 0 --showParse --showDiff fr histoire.txt`

  The sentences of the French file *histoire.txt* are displayed with their parse (in CONLLU and as a tree). The sentence is regenerated and the differences between the regenerated sentence and the original are displayed. Because of the `-n 0`, no *shifted* content is displayed.

   
